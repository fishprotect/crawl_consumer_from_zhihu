# crawl_consumer_from_zhihu
## 1 zhihu
### 用scrapy爬取用户数据


## 2 zhihu_phantomjs_selenium:
### 使用phantomjs和selenium,驱动浏览器爬取
### 须安装redis和mongoDB
#### 代爬取的url放在redis中，爬取结果存贮在mongodb中
